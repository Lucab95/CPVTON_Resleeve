{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "initial_path= os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(Path(initial_path).parent)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "from test import *\n",
    "import sys\n",
    "# sys.path.append('..')\n",
    "from src.data.cp_dataset import CPDataset, CPDataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "from src.models.networks import GMM, UnetGenerator,load_checkpoint\n",
    "#bring the working directory to the top\n",
    "import time\n",
    "# os.chdir(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opt():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--name\", default=\"GMM\")\n",
    "    # parser.add_argument(\"--name\", default=\"TOM\")\n",
    "\n",
    "    parser.add_argument(\"--gpu_ids\", default=\"1\")\n",
    "    parser.add_argument('-j', '--workers', type=int, default=1)\n",
    "    parser.add_argument('-b', '--batch-size', type=int, default=4)\n",
    "\n",
    "    parser.add_argument(\"--dataroot\", default=\"data\")\n",
    "\n",
    "    parser.add_argument(\"--datamode\", default=\"test\", choices=[\"test\", \"wild\"])\n",
    "\n",
    "    parser.add_argument(\"--stage\", default=\"GMM\")\n",
    "    # parser.add_argument(\"--stage\", default=\"TOM\")\n",
    "\n",
    "    parser.add_argument(\"--data_list\", default=\"test_pairs.txt\")\n",
    "    # parser.add_argument(\"--data_list\", default=\"test_pairs_same.txt\")\n",
    "\n",
    "    parser.add_argument(\"--fine_width\", type=int, default=192)\n",
    "    parser.add_argument(\"--fine_height\", type=int, default=256)\n",
    "    parser.add_argument(\"--radius\", type=int, default=5)\n",
    "    parser.add_argument(\"--grid_size\", type=int, default=5)\n",
    "\n",
    "    parser.add_argument('--tensorboard_dir', type=str, default='tensortest', help='save tensorboard infos')\n",
    "\n",
    "    parser.add_argument('--result_dir', type=str,default='result', help='save result infos')\n",
    "\n",
    "    parser.add_argument('--checkpoint_GMM', type=str, default='checkpoints/GMM/gmm_final.pth', help='model checkpoint for test')\n",
    "    parser.add_argument('--checkpoint_TOM', type=str, default='checkpoints/TOM/tom_final.pth', help='model checkpoint for test')\n",
    "\n",
    "    parser.add_argument(\"--display_count\", type=int, default=1)\n",
    "    parser.add_argument(\"--shuffle\", action='store_true',default=True,\n",
    "                        help='shuffle input data')\n",
    "\n",
    "    opt = parser.parse_args(args=[])\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = get_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to test stage: GMM, named: GMM!\n"
     ]
    }
   ],
   "source": [
    "print(\"Start to test stage: %s, named: %s!\" % (opt.stage, opt.name))\n",
    "test_dataset = CPDataset(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=opt.batch_size, shuffle=opt.shuffle, num_workers=opt.workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(opt.tensorboard_dir):\n",
    "        os.makedirs(opt.tensorboard_dir)\n",
    "board = SummaryWriter(logdir=os.path.join(opt.tensorboard_dir, opt.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization method [normal]\n",
      "initialization method [normal]\n"
     ]
    }
   ],
   "source": [
    "model_gmm = GMM(opt)\n",
    "model_gmm.cuda()\n",
    "model_gmm.eval()\n",
    "load_checkpoint(model_gmm, opt.checkpoint_GMM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def save_images(img_tensors, img_names, save_dir):\n",
    "    for img_tensor, img_name in zip(img_tensors, img_names):\n",
    "        tensor = (img_tensor.clone()+1)*0.5 * 255\n",
    "        tensor = tensor.cpu().clamp(0, 255)\n",
    "\n",
    "        array = tensor.numpy().astype('uint8')\n",
    "        if array.shape[0] == 1:\n",
    "            array = array.squeeze(0)\n",
    "        elif array.shape[0] == 3:\n",
    "            array = array.swapaxes(0, 1).swapaxes(1, 2)\n",
    "\n",
    "        Image.fromarray(array).save(os.path.join(save_dir, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = os.path.basename(opt.checkpoint_GMM)\n",
    "name = opt.name\n",
    "save_dir = os.path.join(opt.result_dir, name, opt.datamode)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "warp_cloth_dir = os.path.join(save_dir, 'warp-cloth')\n",
    "if not os.path.exists(warp_cloth_dir):\n",
    "    os.makedirs(warp_cloth_dir)\n",
    "warp_mask_dir = os.path.join(save_dir, 'warp-mask')\n",
    "if not os.path.exists(warp_mask_dir):\n",
    "    os.makedirs(warp_mask_dir)\n",
    "result_dir1 = os.path.join(save_dir, 'result_dir')\n",
    "if not os.path.exists(result_dir1):\n",
    "    os.makedirs(result_dir1)\n",
    "overlayed_TPS_dir = os.path.join(save_dir, 'overlayed_TPS')\n",
    "if not os.path.exists(overlayed_TPS_dir):\n",
    "    os.makedirs(overlayed_TPS_dir)\n",
    "warped_grid_dir = os.path.join(save_dir, 'warped_grid')\n",
    "if not os.path.exists(warped_grid_dir):\n",
    "    os.makedirs(warped_grid_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:        1, time: 2.925\n",
      "step:        2, time: 0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luca9\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\functional.py:4194: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  \"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:        3, time: 0.120\n",
      "step:        4, time: 0.146\n",
      "step:        5, time: 0.119\n",
      "step:        6, time: 0.119\n",
      "step:        7, time: 0.115\n",
      "step:        8, time: 0.120\n",
      "step:        9, time: 0.119\n",
      "step:       10, time: 0.129\n",
      "step:       11, time: 0.119\n",
      "step:       12, time: 0.118\n",
      "step:       13, time: 0.114\n",
      "step:       14, time: 0.155\n",
      "step:       15, time: 0.119\n",
      "step:       16, time: 0.126\n",
      "step:       17, time: 0.130\n",
      "step:       18, time: 0.121\n",
      "step:       19, time: 0.127\n",
      "step:       20, time: 0.121\n",
      "step:       21, time: 0.141\n",
      "step:       22, time: 0.135\n",
      "step:       23, time: 0.126\n",
      "step:       24, time: 0.119\n",
      "step:       25, time: 0.172\n",
      "step:       26, time: 0.162\n",
      "step:       27, time: 0.147\n",
      "step:       28, time: 0.110\n",
      "step:       29, time: 0.109\n",
      "step:       30, time: 0.105\n",
      "step:       31, time: 0.114\n",
      "step:       32, time: 0.104\n",
      "step:       33, time: 0.105\n",
      "step:       34, time: 0.096\n",
      "step:       35, time: 0.101\n",
      "step:       36, time: 0.100\n",
      "step:       37, time: 0.100\n",
      "step:       38, time: 0.094\n",
      "step:       39, time: 0.107\n",
      "step:       40, time: 0.165\n",
      "step:       41, time: 0.107\n",
      "step:       42, time: 0.102\n",
      "step:       43, time: 0.123\n",
      "step:       44, time: 0.098\n",
      "step:       45, time: 0.101\n",
      "step:       46, time: 0.102\n",
      "step:       47, time: 0.131\n",
      "step:       48, time: 0.101\n",
      "step:       49, time: 0.096\n",
      "step:       50, time: 0.096\n",
      "step:       51, time: 0.097\n",
      "step:       52, time: 0.112\n",
      "step:       53, time: 0.099\n",
      "step:       54, time: 0.094\n",
      "step:       55, time: 0.131\n",
      "step:       56, time: 0.131\n",
      "step:       57, time: 0.090\n",
      "step:       58, time: 0.096\n",
      "step:       59, time: 0.094\n",
      "step:       60, time: 0.091\n",
      "step:       61, time: 0.098\n",
      "step:       62, time: 0.103\n",
      "step:       63, time: 0.093\n",
      "step:       64, time: 0.091\n",
      "step:       65, time: 0.091\n",
      "step:       66, time: 0.090\n",
      "step:       67, time: 0.099\n",
      "step:       68, time: 0.089\n",
      "step:       69, time: 0.088\n",
      "step:       70, time: 0.090\n",
      "step:       71, time: 0.090\n",
      "step:       72, time: 0.091\n",
      "step:       73, time: 0.095\n",
      "step:       74, time: 0.094\n",
      "step:       75, time: 0.093\n",
      "step:       76, time: 0.097\n",
      "step:       77, time: 0.108\n",
      "step:       78, time: 0.100\n",
      "step:       79, time: 0.096\n",
      "step:       80, time: 0.095\n",
      "step:       81, time: 0.098\n",
      "step:       82, time: 0.105\n",
      "step:       83, time: 0.148\n",
      "step:       84, time: 0.106\n",
      "step:       85, time: 0.101\n",
      "step:       86, time: 0.092\n",
      "step:       87, time: 0.090\n",
      "step:       88, time: 0.090\n",
      "step:       89, time: 0.094\n",
      "step:       90, time: 0.098\n",
      "step:       91, time: 0.091\n",
      "step:       92, time: 0.089\n",
      "step:       93, time: 0.087\n",
      "step:       94, time: 0.089\n",
      "step:       95, time: 0.090\n",
      "step:       96, time: 0.090\n",
      "step:       97, time: 0.116\n",
      "step:       98, time: 0.094\n",
      "step:       99, time: 0.095\n",
      "step:      100, time: 0.104\n",
      "step:      101, time: 0.094\n",
      "step:      102, time: 0.097\n",
      "step:      103, time: 0.099\n",
      "step:      104, time: 0.096\n",
      "step:      105, time: 0.097\n",
      "step:      106, time: 0.100\n",
      "step:      107, time: 0.141\n",
      "step:      108, time: 0.121\n",
      "step:      109, time: 0.091\n",
      "step:      110, time: 0.093\n",
      "step:      111, time: 0.091\n",
      "step:      112, time: 0.101\n",
      "step:      113, time: 0.095\n",
      "step:      114, time: 0.090\n",
      "step:      115, time: 0.090\n",
      "step:      116, time: 0.091\n",
      "step:      117, time: 0.088\n",
      "step:      118, time: 0.095\n",
      "step:      119, time: 0.099\n",
      "step:      120, time: 0.092\n",
      "step:      121, time: 0.092\n",
      "step:      122, time: 0.092\n",
      "step:      123, time: 0.091\n",
      "step:      124, time: 0.092\n",
      "step:      125, time: 0.093\n",
      "step:      126, time: 0.093\n",
      "step:      127, time: 0.094\n",
      "step:      128, time: 0.097\n",
      "step:      129, time: 0.096\n",
      "step:      130, time: 0.094\n",
      "step:      131, time: 0.101\n",
      "step:      132, time: 0.093\n",
      "step:      133, time: 0.122\n",
      "step:      134, time: 0.148\n",
      "step:      135, time: 0.098\n",
      "step:      136, time: 0.106\n",
      "step:      137, time: 0.099\n",
      "step:      138, time: 0.092\n",
      "step:      139, time: 0.090\n",
      "step:      140, time: 0.091\n",
      "step:      141, time: 0.090\n",
      "step:      142, time: 0.098\n",
      "step:      143, time: 0.089\n",
      "step:      144, time: 0.090\n",
      "step:      145, time: 0.086\n",
      "step:      146, time: 0.107\n",
      "step:      147, time: 0.090\n",
      "step:      148, time: 0.089\n",
      "step:      149, time: 0.091\n",
      "step:      150, time: 0.098\n",
      "step:      151, time: 0.094\n",
      "step:      152, time: 0.124\n",
      "step:      153, time: 0.102\n",
      "step:      154, time: 0.094\n",
      "step:      155, time: 0.093\n",
      "step:      156, time: 0.106\n",
      "step:      157, time: 0.097\n",
      "step:      158, time: 0.103\n",
      "step:      159, time: 0.090\n",
      "step:      160, time: 0.087\n",
      "step:      161, time: 0.091\n",
      "step:      162, time: 0.093\n",
      "step:      163, time: 0.094\n",
      "step:      164, time: 0.093\n",
      "step:      165, time: 0.093\n",
      "step:      166, time: 0.096\n",
      "step:      167, time: 0.099\n",
      "step:      168, time: 0.103\n",
      "step:      169, time: 0.100\n",
      "step:      170, time: 0.137\n",
      "step:      171, time: 0.093\n",
      "step:      172, time: 0.095\n",
      "step:      173, time: 0.104\n",
      "step:      174, time: 0.101\n",
      "step:      175, time: 0.103\n",
      "step:      176, time: 0.109\n",
      "step:      177, time: 0.100\n",
      "step:      178, time: 0.108\n",
      "step:      179, time: 0.105\n",
      "step:      180, time: 0.102\n",
      "step:      181, time: 0.102\n",
      "step:      182, time: 0.106\n",
      "step:      183, time: 0.110\n",
      "step:      184, time: 0.093\n",
      "step:      185, time: 0.143\n",
      "step:      186, time: 0.120\n",
      "step:      187, time: 0.102\n",
      "step:      188, time: 0.100\n",
      "step:      189, time: 0.121\n",
      "step:      190, time: 0.106\n",
      "step:      191, time: 0.106\n",
      "step:      192, time: 0.104\n",
      "step:      193, time: 0.106\n",
      "step:      194, time: 0.129\n",
      "step:      195, time: 0.111\n",
      "step:      196, time: 0.096\n",
      "step:      197, time: 0.097\n",
      "step:      198, time: 0.104\n",
      "step:      199, time: 0.114\n",
      "step:      200, time: 0.147\n",
      "step:      201, time: 0.100\n",
      "step:      202, time: 0.113\n",
      "step:      203, time: 0.110\n",
      "step:      204, time: 0.113\n",
      "step:      205, time: 0.104\n",
      "step:      206, time: 0.100\n",
      "step:      207, time: 0.093\n",
      "step:      208, time: 0.097\n",
      "step:      209, time: 0.096\n",
      "step:      210, time: 0.094\n",
      "step:      211, time: 0.093\n",
      "step:      212, time: 0.095\n",
      "step:      213, time: 0.094\n",
      "step:      214, time: 0.095\n",
      "step:      215, time: 0.098\n",
      "step:      216, time: 0.098\n",
      "step:      217, time: 0.095\n",
      "step:      218, time: 0.099\n",
      "step:      219, time: 0.142\n",
      "step:      220, time: 0.109\n",
      "step:      221, time: 0.125\n",
      "step:      222, time: 0.111\n",
      "step:      223, time: 0.099\n",
      "step:      224, time: 0.097\n",
      "step:      225, time: 0.100\n",
      "step:      226, time: 0.101\n",
      "step:      227, time: 0.106\n",
      "step:      228, time: 0.106\n",
      "step:      229, time: 0.098\n",
      "step:      230, time: 0.091\n",
      "step:      231, time: 0.097\n",
      "step:      232, time: 0.100\n",
      "step:      233, time: 0.103\n",
      "step:      234, time: 0.138\n",
      "step:      235, time: 0.134\n",
      "step:      236, time: 0.105\n",
      "step:      237, time: 0.098\n",
      "step:      238, time: 0.096\n",
      "step:      239, time: 0.107\n",
      "step:      240, time: 0.105\n",
      "step:      241, time: 0.101\n",
      "step:      242, time: 0.132\n",
      "step:      243, time: 0.115\n",
      "step:      244, time: 0.114\n",
      "step:      245, time: 0.094\n",
      "step:      246, time: 0.095\n",
      "step:      247, time: 0.100\n",
      "step:      248, time: 0.099\n",
      "step:      249, time: 0.101\n",
      "step:      250, time: 0.100\n",
      "step:      251, time: 0.100\n",
      "step:      252, time: 0.104\n",
      "step:      253, time: 0.149\n",
      "step:      254, time: 0.136\n",
      "step:      255, time: 0.092\n",
      "step:      256, time: 0.092\n",
      "step:      257, time: 0.087\n",
      "step:      258, time: 0.093\n",
      "step:      259, time: 0.092\n",
      "step:      260, time: 0.110\n",
      "step:      261, time: 0.093\n",
      "step:      262, time: 0.104\n",
      "step:      263, time: 0.121\n",
      "step:      264, time: 0.098\n",
      "step:      265, time: 0.096\n",
      "step:      266, time: 0.097\n",
      "step:      267, time: 0.100\n",
      "step:      268, time: 0.101\n",
      "step:      269, time: 0.099\n",
      "step:      270, time: 0.103\n",
      "step:      271, time: 0.095\n",
      "step:      272, time: 0.113\n",
      "step:      273, time: 0.097\n",
      "step:      274, time: 0.096\n",
      "step:      275, time: 0.103\n",
      "step:      276, time: 0.107\n",
      "step:      277, time: 0.105\n",
      "step:      278, time: 0.099\n",
      "step:      279, time: 0.126\n",
      "step:      280, time: 0.159\n",
      "step:      281, time: 0.126\n",
      "step:      282, time: 0.125\n",
      "step:      283, time: 0.112\n",
      "step:      284, time: 0.114\n",
      "step:      285, time: 0.098\n",
      "step:      286, time: 0.099\n",
      "step:      287, time: 0.094\n",
      "step:      288, time: 0.095\n",
      "step:      289, time: 0.095\n",
      "step:      290, time: 0.101\n",
      "step:      291, time: 0.103\n",
      "step:      292, time: 0.096\n",
      "step:      293, time: 0.100\n",
      "step:      294, time: 0.097\n",
      "step:      295, time: 0.135\n",
      "step:      296, time: 0.105\n",
      "step:      297, time: 0.091\n",
      "step:      298, time: 0.092\n",
      "step:      299, time: 0.094\n",
      "step:      300, time: 0.093\n",
      "step:      301, time: 0.101\n",
      "step:      302, time: 0.092\n",
      "step:      303, time: 0.113\n",
      "step:      304, time: 0.098\n",
      "step:      305, time: 0.094\n",
      "step:      306, time: 0.098\n",
      "step:      307, time: 0.093\n",
      "step:      308, time: 0.097\n",
      "step:      309, time: 0.099\n",
      "step:      310, time: 0.094\n",
      "step:      311, time: 0.093\n",
      "step:      312, time: 0.098\n",
      "step:      313, time: 0.097\n",
      "step:      314, time: 0.128\n",
      "step:      315, time: 0.137\n",
      "step:      316, time: 0.089\n",
      "step:      317, time: 0.091\n",
      "step:      318, time: 0.092\n",
      "step:      319, time: 0.090\n",
      "step:      320, time: 0.088\n",
      "step:      321, time: 0.086\n",
      "step:      322, time: 0.089\n",
      "step:      323, time: 0.091\n",
      "step:      324, time: 0.088\n",
      "step:      325, time: 0.091\n",
      "step:      326, time: 0.089\n",
      "step:      327, time: 0.088\n",
      "step:      328, time: 0.090\n",
      "step:      329, time: 0.086\n",
      "step:      330, time: 0.088\n",
      "step:      331, time: 0.087\n",
      "step:      332, time: 0.108\n",
      "step:      333, time: 0.094\n",
      "step:      334, time: 0.101\n",
      "step:      335, time: 0.098\n",
      "step:      336, time: 0.094\n",
      "step:      337, time: 0.095\n",
      "step:      338, time: 0.097\n",
      "step:      339, time: 0.104\n",
      "step:      340, time: 0.103\n",
      "step:      341, time: 0.126\n",
      "step:      342, time: 0.093\n",
      "step:      343, time: 0.093\n",
      "step:      344, time: 0.098\n",
      "step:      345, time: 0.100\n",
      "step:      346, time: 0.101\n",
      "step:      347, time: 0.095\n",
      "step:      348, time: 0.102\n",
      "step:      349, time: 0.094\n",
      "step:      350, time: 0.099\n",
      "step:      351, time: 0.102\n",
      "step:      352, time: 0.097\n",
      "step:      353, time: 0.099\n",
      "step:      354, time: 0.104\n",
      "step:      355, time: 0.110\n",
      "step:      356, time: 0.109\n",
      "step:      357, time: 0.116\n",
      "step:      358, time: 0.146\n",
      "step:      359, time: 0.120\n",
      "step:      360, time: 0.108\n",
      "step:      361, time: 0.096\n",
      "step:      362, time: 0.098\n",
      "step:      363, time: 0.099\n",
      "step:      364, time: 0.113\n",
      "step:      365, time: 0.103\n",
      "step:      366, time: 0.093\n",
      "step:      367, time: 0.096\n",
      "step:      368, time: 0.099\n",
      "step:      369, time: 0.102\n",
      "step:      370, time: 0.095\n",
      "step:      371, time: 0.095\n",
      "step:      372, time: 0.096\n",
      "step:      373, time: 0.105\n",
      "step:      374, time: 0.148\n",
      "step:      375, time: 0.107\n",
      "step:      376, time: 0.107\n",
      "step:      377, time: 0.102\n",
      "step:      378, time: 0.116\n",
      "step:      379, time: 0.107\n",
      "step:      380, time: 0.101\n",
      "step:      381, time: 0.098\n",
      "step:      382, time: 0.113\n",
      "step:      383, time: 0.129\n",
      "step:      384, time: 0.102\n",
      "step:      385, time: 0.111\n",
      "step:      386, time: 0.108\n",
      "step:      387, time: 0.112\n",
      "step:      388, time: 0.108\n",
      "step:      389, time: 0.135\n",
      "step:      390, time: 0.094\n",
      "step:      391, time: 0.101\n",
      "step:      392, time: 0.103\n",
      "step:      393, time: 0.104\n",
      "step:      394, time: 0.094\n",
      "step:      395, time: 0.107\n",
      "step:      396, time: 0.100\n",
      "step:      397, time: 0.094\n",
      "step:      398, time: 0.094\n",
      "step:      399, time: 0.107\n",
      "step:      400, time: 0.091\n",
      "step:      401, time: 0.093\n",
      "step:      402, time: 0.093\n",
      "step:      403, time: 0.091\n",
      "step:      404, time: 0.098\n",
      "step:      405, time: 0.096\n",
      "step:      406, time: 0.149\n",
      "step:      407, time: 0.109\n",
      "step:      408, time: 0.100\n",
      "step:      409, time: 0.090\n",
      "step:      410, time: 0.091\n",
      "step:      411, time: 0.104\n",
      "step:      412, time: 0.100\n",
      "step:      413, time: 0.092\n",
      "step:      414, time: 0.095\n",
      "step:      415, time: 0.093\n",
      "step:      416, time: 0.104\n",
      "step:      417, time: 0.100\n",
      "step:      418, time: 0.099\n",
      "step:      419, time: 0.091\n",
      "step:      420, time: 0.097\n",
      "step:      421, time: 0.097\n",
      "step:      422, time: 0.091\n",
      "step:      423, time: 0.095\n",
      "step:      424, time: 0.098\n",
      "step:      425, time: 0.094\n",
      "step:      426, time: 0.092\n",
      "step:      427, time: 0.093\n",
      "step:      428, time: 0.093\n",
      "step:      429, time: 0.102\n",
      "step:      430, time: 0.093\n",
      "step:      431, time: 0.096\n",
      "step:      432, time: 0.115\n",
      "step:      433, time: 0.126\n",
      "step:      434, time: 0.100\n",
      "step:      435, time: 0.105\n",
      "step:      436, time: 0.090\n",
      "step:      437, time: 0.090\n",
      "step:      438, time: 0.089\n",
      "step:      439, time: 0.089\n",
      "step:      440, time: 0.093\n",
      "step:      441, time: 0.097\n",
      "step:      442, time: 0.101\n",
      "step:      443, time: 0.089\n",
      "step:      444, time: 0.091\n",
      "step:      445, time: 0.098\n",
      "step:      446, time: 0.092\n",
      "step:      447, time: 0.094\n",
      "step:      448, time: 0.091\n",
      "step:      449, time: 0.098\n",
      "step:      450, time: 0.092\n",
      "step:      451, time: 0.110\n",
      "step:      452, time: 0.108\n",
      "step:      453, time: 0.103\n",
      "step:      454, time: 0.120\n",
      "step:      455, time: 0.131\n",
      "step:      456, time: 0.095\n",
      "step:      457, time: 0.097\n",
      "step:      458, time: 0.091\n",
      "step:      459, time: 0.092\n",
      "step:      460, time: 0.109\n",
      "step:      461, time: 0.101\n",
      "step:      462, time: 0.093\n",
      "step:      463, time: 0.097\n",
      "step:      464, time: 0.098\n",
      "step:      465, time: 0.095\n",
      "step:      466, time: 0.106\n",
      "step:      467, time: 0.096\n",
      "step:      468, time: 0.103\n",
      "step:      469, time: 0.094\n",
      "step:      470, time: 0.091\n",
      "step:      471, time: 0.093\n",
      "step:      472, time: 0.098\n",
      "step:      473, time: 0.143\n",
      "step:      474, time: 0.115\n",
      "step:      475, time: 0.107\n",
      "step:      476, time: 0.094\n",
      "step:      477, time: 0.089\n",
      "step:      478, time: 0.087\n",
      "step:      479, time: 0.094\n",
      "step:      480, time: 0.099\n",
      "step:      481, time: 0.091\n",
      "step:      482, time: 0.089\n",
      "step:      483, time: 0.094\n",
      "step:      484, time: 0.094\n",
      "step:      485, time: 0.095\n",
      "step:      486, time: 0.095\n",
      "step:      487, time: 0.091\n",
      "step:      488, time: 0.092\n",
      "step:      489, time: 0.094\n",
      "step:      490, time: 0.097\n",
      "step:      491, time: 0.103\n",
      "step:      492, time: 0.096\n",
      "step:      493, time: 0.097\n",
      "step:      494, time: 0.117\n",
      "step:      495, time: 0.128\n",
      "step:      496, time: 0.092\n",
      "step:      497, time: 0.090\n",
      "step:      498, time: 0.094\n",
      "step:      499, time: 0.099\n",
      "step:      500, time: 0.103\n",
      "step:      501, time: 0.090\n",
      "step:      502, time: 0.087\n",
      "step:      503, time: 0.090\n",
      "step:      504, time: 0.084\n",
      "step:      505, time: 0.086\n",
      "step:      506, time: 0.086\n",
      "step:      507, time: 0.089\n",
      "step:      508, time: 0.083\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for step, inputs in enumerate(test_loader):\n",
    "        iter_start_time = time.time()\n",
    "       \n",
    "\n",
    "        c_names = inputs['c_name']\n",
    "        im_names = inputs['im_name']\n",
    "        im = inputs['image'].cuda()\n",
    "        im_pose = inputs['pose_image'].cuda()\n",
    "        im_h = inputs['head'].cuda()\n",
    "        shape = inputs['shape'].cuda()\n",
    "        agnostic = inputs['agnostic'].cuda()\n",
    "        c = inputs['cloth'].cuda()\n",
    "        cm = inputs['cloth_mask'].cuda()\n",
    "        im_c = inputs['parse_cloth'].cuda()\n",
    "        im_g = inputs['grid_image'].cuda()\n",
    "        shape_ori = inputs['shape_ori']  # original body shape without blurring\n",
    "\n",
    "        grid, theta = model_gmm(agnostic, cm)\n",
    "        warped_cloth = F.grid_sample(c, grid, padding_mode='border')\n",
    "        warped_mask = F.grid_sample(cm, grid, padding_mode='zeros')\n",
    "        warped_grid = F.grid_sample(im_g, grid, padding_mode='zeros')\n",
    "        overlay = 0.7 * warped_cloth + 0.3 * im\n",
    "\n",
    "        visuals = [[im_h, shape, im_pose],\n",
    "                    [c, warped_cloth, im_c],\n",
    "                    [warped_grid, (warped_cloth+im)*0.5, im]]\n",
    "\n",
    "        # save_images(warped_cloth, c_names, warp_cloth_dir)\n",
    "        # save_images(warped_mask*2-1, c_names, warp_mask_dir)\n",
    "        save_images(warped_cloth, im_names, warp_cloth_dir)\n",
    "        save_images(warped_mask * 2 - 1, im_names, warp_mask_dir)\n",
    "        save_images(shape_ori.cuda() * 0.2 + warped_cloth *\n",
    "                    0.8, im_names, result_dir1)\n",
    "        save_images(warped_grid, im_names, warped_grid_dir)\n",
    "        save_images(overlay, im_names, overlayed_TPS_dir)\n",
    "\n",
    "        if (step+1) % opt.display_count == 0:\n",
    "            # board_add_images(board, 'combine', visuals, step+1)\n",
    "            t = time.time() - iter_start_time\n",
    "            print('step: %8d, time: %.3f' % (step+1, t), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:        1, time: 0.147\n",
      "step:        2, time: 0.138\n",
      "step:        3, time: 0.140\n",
      "step:        4, time: 0.113\n",
      "step:        5, time: 0.090\n",
      "step:        6, time: 0.086\n",
      "step:        7, time: 0.087\n",
      "step:        8, time: 0.087\n",
      "step:        9, time: 0.083\n",
      "step:       10, time: 0.087\n",
      "step:       11, time: 0.088\n",
      "step:       12, time: 0.093\n",
      "step:       13, time: 0.098\n",
      "step:       14, time: 0.087\n",
      "step:       15, time: 0.086\n",
      "step:       16, time: 0.086\n",
      "step:       17, time: 0.084\n",
      "step:       18, time: 0.094\n",
      "step:       19, time: 0.094\n",
      "step:       20, time: 0.087\n",
      "step:       21, time: 0.083\n",
      "step:       22, time: 0.083\n",
      "step:       23, time: 0.090\n",
      "step:       24, time: 0.090\n",
      "step:       25, time: 0.094\n",
      "step:       26, time: 0.091\n",
      "step:       27, time: 0.093\n",
      "step:       28, time: 0.089\n",
      "step:       29, time: 0.087\n",
      "step:       30, time: 0.087\n",
      "step:       31, time: 0.086\n",
      "step:       32, time: 0.089\n",
      "step:       33, time: 0.090\n",
      "step:       34, time: 0.090\n",
      "step:       35, time: 0.089\n",
      "step:       36, time: 0.090\n",
      "step:       37, time: 0.096\n",
      "step:       38, time: 0.088\n",
      "step:       39, time: 0.093\n",
      "step:       40, time: 0.092\n",
      "step:       41, time: 0.123\n",
      "step:       42, time: 0.108\n",
      "step:       43, time: 0.101\n",
      "step:       44, time: 0.094\n",
      "step:       45, time: 0.091\n",
      "step:       46, time: 0.094\n",
      "step:       47, time: 0.092\n",
      "step:       48, time: 0.091\n",
      "step:       49, time: 0.107\n",
      "step:       50, time: 0.108\n",
      "step:       51, time: 0.094\n",
      "step:       52, time: 0.090\n",
      "step:       53, time: 0.090\n",
      "step:       54, time: 0.089\n",
      "step:       55, time: 0.091\n",
      "step:       56, time: 0.100\n",
      "step:       57, time: 0.094\n",
      "step:       58, time: 0.091\n",
      "step:       59, time: 0.091\n",
      "step:       60, time: 0.125\n",
      "step:       61, time: 0.123\n",
      "step:       62, time: 0.086\n",
      "step:       63, time: 0.085\n",
      "step:       64, time: 0.088\n",
      "step:       65, time: 0.089\n",
      "step:       66, time: 0.086\n",
      "step:       67, time: 0.090\n",
      "step:       68, time: 0.086\n",
      "step:       69, time: 0.087\n",
      "step:       70, time: 0.084\n",
      "step:       71, time: 0.083\n",
      "step:       72, time: 0.095\n",
      "step:       73, time: 0.088\n",
      "step:       74, time: 0.082\n",
      "step:       75, time: 0.087\n",
      "step:       76, time: 0.080\n",
      "step:       77, time: 0.084\n",
      "step:       78, time: 0.098\n",
      "step:       79, time: 0.097\n",
      "step:       80, time: 0.089\n",
      "step:       81, time: 0.087\n",
      "step:       82, time: 0.085\n",
      "step:       83, time: 0.087\n",
      "step:       84, time: 0.091\n",
      "step:       85, time: 0.102\n",
      "step:       86, time: 0.090\n",
      "step:       87, time: 0.089\n",
      "step:       88, time: 0.089\n",
      "step:       89, time: 0.092\n",
      "step:       90, time: 0.092\n",
      "step:       91, time: 0.093\n",
      "step:       92, time: 0.091\n",
      "step:       93, time: 0.088\n",
      "step:       94, time: 0.106\n",
      "step:       95, time: 0.098\n",
      "step:       96, time: 0.093\n",
      "step:       97, time: 0.103\n",
      "step:       98, time: 0.095\n",
      "step:       99, time: 0.097\n",
      "step:      100, time: 0.088\n",
      "step:      101, time: 0.093\n",
      "step:      102, time: 0.091\n",
      "step:      103, time: 0.091\n",
      "step:      104, time: 0.096\n",
      "step:      105, time: 0.094\n",
      "step:      106, time: 0.097\n",
      "step:      107, time: 0.098\n",
      "step:      108, time: 0.103\n",
      "step:      109, time: 0.092\n",
      "step:      110, time: 0.092\n",
      "step:      111, time: 0.091\n",
      "step:      112, time: 0.093\n",
      "step:      113, time: 0.109\n",
      "step:      114, time: 0.111\n",
      "step:      115, time: 0.102\n",
      "step:      116, time: 0.098\n",
      "step:      117, time: 0.100\n",
      "step:      118, time: 0.100\n",
      "step:      119, time: 0.108\n",
      "step:      120, time: 0.151\n",
      "step:      121, time: 0.138\n",
      "step:      122, time: 0.102\n",
      "step:      123, time: 0.101\n",
      "step:      124, time: 0.084\n",
      "step:      125, time: 0.090\n",
      "step:      126, time: 0.089\n",
      "step:      127, time: 0.087\n",
      "step:      128, time: 0.110\n",
      "step:      129, time: 0.102\n",
      "step:      130, time: 0.089\n",
      "step:      131, time: 0.088\n",
      "step:      132, time: 0.085\n",
      "step:      133, time: 0.085\n",
      "step:      134, time: 0.086\n",
      "step:      135, time: 0.085\n",
      "step:      136, time: 0.088\n",
      "step:      137, time: 0.086\n",
      "step:      138, time: 0.083\n",
      "step:      139, time: 0.087\n",
      "step:      140, time: 0.095\n",
      "step:      141, time: 0.095\n",
      "step:      142, time: 0.091\n",
      "step:      143, time: 0.092\n",
      "step:      144, time: 0.097\n",
      "step:      145, time: 0.089\n",
      "step:      146, time: 0.092\n",
      "step:      147, time: 0.101\n",
      "step:      148, time: 0.094\n",
      "step:      149, time: 0.092\n",
      "step:      150, time: 0.100\n",
      "step:      151, time: 0.091\n",
      "step:      152, time: 0.109\n",
      "step:      153, time: 0.092\n",
      "step:      154, time: 0.095\n",
      "step:      155, time: 0.102\n",
      "step:      156, time: 0.101\n",
      "step:      157, time: 0.117\n",
      "step:      158, time: 0.108\n",
      "step:      159, time: 0.104\n",
      "step:      160, time: 0.104\n",
      "step:      161, time: 0.112\n",
      "step:      162, time: 0.103\n",
      "step:      163, time: 0.117\n",
      "step:      164, time: 0.099\n",
      "step:      165, time: 0.097\n",
      "step:      166, time: 0.089\n",
      "step:      167, time: 0.092\n",
      "step:      168, time: 0.093\n",
      "step:      169, time: 0.094\n",
      "step:      170, time: 0.091\n",
      "step:      171, time: 0.093\n",
      "step:      172, time: 0.097\n",
      "step:      173, time: 0.092\n",
      "step:      174, time: 0.132\n",
      "step:      175, time: 0.126\n",
      "step:      176, time: 0.086\n",
      "step:      177, time: 0.086\n",
      "step:      178, time: 0.084\n",
      "step:      179, time: 0.084\n",
      "step:      180, time: 0.085\n",
      "step:      181, time: 0.085\n",
      "step:      182, time: 0.084\n",
      "step:      183, time: 0.086\n",
      "step:      184, time: 0.097\n",
      "step:      185, time: 0.086\n",
      "step:      186, time: 0.088\n",
      "step:      187, time: 0.089\n",
      "step:      188, time: 0.084\n",
      "step:      189, time: 0.092\n",
      "step:      190, time: 0.089\n",
      "step:      191, time: 0.089\n",
      "step:      192, time: 0.098\n",
      "step:      193, time: 0.092\n",
      "step:      194, time: 0.091\n",
      "step:      195, time: 0.087\n",
      "step:      196, time: 0.087\n",
      "step:      197, time: 0.094\n",
      "step:      198, time: 0.101\n",
      "step:      199, time: 0.095\n",
      "step:      200, time: 0.094\n",
      "step:      201, time: 0.090\n",
      "step:      202, time: 0.088\n",
      "step:      203, time: 0.091\n",
      "step:      204, time: 0.099\n",
      "step:      205, time: 0.093\n",
      "step:      206, time: 0.093\n",
      "step:      207, time: 0.088\n",
      "step:      208, time: 0.092\n",
      "step:      209, time: 0.094\n",
      "step:      210, time: 0.092\n",
      "step:      211, time: 0.088\n",
      "step:      212, time: 0.092\n",
      "step:      213, time: 0.090\n",
      "step:      214, time: 0.093\n",
      "step:      215, time: 0.091\n",
      "step:      216, time: 0.088\n",
      "step:      217, time: 0.092\n",
      "step:      218, time: 0.091\n",
      "step:      219, time: 0.092\n",
      "step:      220, time: 0.097\n",
      "step:      221, time: 0.092\n",
      "step:      222, time: 0.092\n",
      "step:      223, time: 0.093\n",
      "step:      224, time: 0.090\n",
      "step:      225, time: 0.094\n",
      "step:      226, time: 0.100\n",
      "step:      227, time: 0.106\n",
      "step:      228, time: 0.098\n",
      "step:      229, time: 0.132\n",
      "step:      230, time: 0.133\n",
      "step:      231, time: 0.100\n",
      "step:      232, time: 0.091\n",
      "step:      233, time: 0.109\n",
      "step:      234, time: 0.105\n",
      "step:      235, time: 0.097\n",
      "step:      236, time: 0.115\n",
      "step:      237, time: 0.109\n",
      "step:      238, time: 0.106\n",
      "step:      239, time: 0.103\n",
      "step:      240, time: 0.092\n",
      "step:      241, time: 0.087\n",
      "step:      242, time: 0.089\n",
      "step:      243, time: 0.090\n",
      "step:      244, time: 0.099\n",
      "step:      245, time: 0.094\n",
      "step:      246, time: 0.113\n",
      "step:      247, time: 0.094\n",
      "step:      248, time: 0.091\n",
      "step:      249, time: 0.091\n",
      "step:      250, time: 0.105\n",
      "step:      251, time: 0.094\n",
      "step:      252, time: 0.094\n",
      "step:      253, time: 0.095\n",
      "step:      254, time: 0.128\n",
      "step:      255, time: 0.118\n",
      "step:      256, time: 0.086\n",
      "step:      257, time: 0.087\n",
      "step:      258, time: 0.083\n",
      "step:      259, time: 0.090\n",
      "step:      260, time: 0.093\n",
      "step:      261, time: 0.101\n",
      "step:      262, time: 0.081\n",
      "step:      263, time: 0.085\n",
      "step:      264, time: 0.095\n",
      "step:      265, time: 0.104\n",
      "step:      266, time: 0.092\n",
      "step:      267, time: 0.110\n",
      "step:      268, time: 0.092\n",
      "step:      269, time: 0.085\n",
      "step:      270, time: 0.086\n",
      "step:      271, time: 0.085\n",
      "step:      272, time: 0.086\n",
      "step:      273, time: 0.087\n",
      "step:      274, time: 0.091\n",
      "step:      275, time: 0.091\n",
      "step:      276, time: 0.091\n",
      "step:      277, time: 0.087\n",
      "step:      278, time: 0.091\n",
      "step:      279, time: 0.090\n",
      "step:      280, time: 0.090\n",
      "step:      281, time: 0.093\n",
      "step:      282, time: 0.090\n",
      "step:      283, time: 0.092\n",
      "step:      284, time: 0.090\n",
      "step:      285, time: 0.100\n",
      "step:      286, time: 0.097\n",
      "step:      287, time: 0.092\n",
      "step:      288, time: 0.090\n",
      "step:      289, time: 0.090\n",
      "step:      290, time: 0.089\n",
      "step:      291, time: 0.092\n",
      "step:      292, time: 0.091\n",
      "step:      293, time: 0.089\n",
      "step:      294, time: 0.095\n",
      "step:      295, time: 0.096\n",
      "step:      296, time: 0.094\n",
      "step:      297, time: 0.093\n",
      "step:      298, time: 0.095\n",
      "step:      299, time: 0.091\n",
      "step:      300, time: 0.102\n",
      "step:      301, time: 0.092\n",
      "step:      302, time: 0.105\n",
      "step:      303, time: 0.100\n",
      "step:      304, time: 0.093\n",
      "step:      305, time: 0.096\n",
      "step:      306, time: 0.096\n",
      "step:      307, time: 0.089\n",
      "step:      308, time: 0.090\n",
      "step:      309, time: 0.091\n",
      "step:      310, time: 0.094\n",
      "step:      311, time: 0.092\n",
      "step:      312, time: 0.092\n",
      "step:      313, time: 0.093\n",
      "step:      314, time: 0.090\n",
      "step:      315, time: 0.090\n",
      "step:      316, time: 0.097\n",
      "step:      317, time: 0.137\n",
      "step:      318, time: 0.099\n",
      "step:      319, time: 0.087\n",
      "step:      320, time: 0.091\n",
      "step:      321, time: 0.089\n",
      "step:      322, time: 0.085\n",
      "step:      323, time: 0.091\n",
      "step:      324, time: 0.091\n",
      "step:      325, time: 0.090\n",
      "step:      326, time: 0.092\n",
      "step:      327, time: 0.091\n",
      "step:      328, time: 0.092\n",
      "step:      329, time: 0.093\n",
      "step:      330, time: 0.096\n",
      "step:      331, time: 0.093\n",
      "step:      332, time: 0.093\n",
      "step:      333, time: 0.088\n",
      "step:      334, time: 0.086\n",
      "step:      335, time: 0.092\n",
      "step:      336, time: 0.087\n",
      "step:      337, time: 0.113\n",
      "step:      338, time: 0.101\n",
      "step:      339, time: 0.092\n",
      "step:      340, time: 0.095\n",
      "step:      341, time: 0.091\n",
      "step:      342, time: 0.091\n",
      "step:      343, time: 0.088\n",
      "step:      344, time: 0.094\n",
      "step:      345, time: 0.091\n",
      "step:      346, time: 0.096\n",
      "step:      347, time: 0.093\n",
      "step:      348, time: 0.091\n",
      "step:      349, time: 0.093\n",
      "step:      350, time: 0.093\n",
      "step:      351, time: 0.093\n",
      "step:      352, time: 0.091\n",
      "step:      353, time: 0.093\n",
      "step:      354, time: 0.093\n",
      "step:      355, time: 0.091\n",
      "step:      356, time: 0.092\n",
      "step:      357, time: 0.132\n",
      "step:      358, time: 0.119\n",
      "step:      359, time: 0.086\n",
      "step:      360, time: 0.089\n",
      "step:      361, time: 0.085\n",
      "step:      362, time: 0.088\n",
      "step:      363, time: 0.089\n",
      "step:      364, time: 0.087\n",
      "step:      365, time: 0.083\n",
      "step:      366, time: 0.095\n",
      "step:      367, time: 0.100\n",
      "step:      368, time: 0.089\n",
      "step:      369, time: 0.086\n",
      "step:      370, time: 0.087\n",
      "step:      371, time: 0.087\n",
      "step:      372, time: 0.087\n",
      "step:      373, time: 0.095\n",
      "step:      374, time: 0.090\n",
      "step:      375, time: 0.085\n",
      "step:      376, time: 0.092\n",
      "step:      377, time: 0.085\n",
      "step:      378, time: 0.088\n",
      "step:      379, time: 0.088\n",
      "step:      380, time: 0.090\n",
      "step:      381, time: 0.085\n",
      "step:      382, time: 0.090\n",
      "step:      383, time: 0.089\n",
      "step:      384, time: 0.090\n",
      "step:      385, time: 0.087\n",
      "step:      386, time: 0.088\n",
      "step:      387, time: 0.089\n",
      "step:      388, time: 0.091\n",
      "step:      389, time: 0.090\n",
      "step:      390, time: 0.091\n",
      "step:      391, time: 0.085\n",
      "step:      392, time: 0.089\n",
      "step:      393, time: 0.090\n",
      "step:      394, time: 0.087\n",
      "step:      395, time: 0.103\n",
      "step:      396, time: 0.099\n",
      "step:      397, time: 0.089\n",
      "step:      398, time: 0.089\n",
      "step:      399, time: 0.091\n",
      "step:      400, time: 0.090\n",
      "step:      401, time: 0.087\n",
      "step:      402, time: 0.090\n",
      "step:      403, time: 0.100\n",
      "step:      404, time: 0.097\n",
      "step:      405, time: 0.094\n",
      "step:      406, time: 0.095\n",
      "step:      407, time: 0.091\n",
      "step:      408, time: 0.096\n",
      "step:      409, time: 0.096\n",
      "step:      410, time: 0.097\n",
      "step:      411, time: 0.093\n",
      "step:      412, time: 0.089\n",
      "step:      413, time: 0.094\n",
      "step:      414, time: 0.092\n",
      "step:      415, time: 0.089\n",
      "step:      416, time: 0.092\n",
      "step:      417, time: 0.095\n",
      "step:      418, time: 0.091\n",
      "step:      419, time: 0.090\n",
      "step:      420, time: 0.093\n",
      "step:      421, time: 0.089\n",
      "step:      422, time: 0.094\n",
      "step:      423, time: 0.092\n",
      "step:      424, time: 0.090\n",
      "step:      425, time: 0.135\n",
      "step:      426, time: 0.109\n",
      "step:      427, time: 0.088\n",
      "step:      428, time: 0.089\n",
      "step:      429, time: 0.094\n",
      "step:      430, time: 0.090\n",
      "step:      431, time: 0.084\n",
      "step:      432, time: 0.088\n",
      "step:      433, time: 0.089\n",
      "step:      434, time: 0.088\n",
      "step:      435, time: 0.089\n",
      "step:      436, time: 0.090\n",
      "step:      437, time: 0.087\n",
      "step:      438, time: 0.089\n",
      "step:      439, time: 0.096\n",
      "step:      440, time: 0.094\n",
      "step:      441, time: 0.085\n",
      "step:      442, time: 0.084\n",
      "step:      443, time: 0.084\n",
      "step:      444, time: 0.086\n",
      "step:      445, time: 0.091\n",
      "step:      446, time: 0.090\n",
      "step:      447, time: 0.088\n",
      "step:      448, time: 0.093\n",
      "step:      449, time: 0.087\n",
      "step:      450, time: 0.092\n",
      "step:      451, time: 0.089\n",
      "step:      452, time: 0.097\n",
      "step:      453, time: 0.087\n",
      "step:      454, time: 0.090\n",
      "step:      455, time: 0.085\n",
      "step:      456, time: 0.089\n",
      "step:      457, time: 0.087\n",
      "step:      458, time: 0.091\n",
      "step:      459, time: 0.089\n",
      "step:      460, time: 0.090\n",
      "step:      461, time: 0.090\n",
      "step:      462, time: 0.090\n",
      "step:      463, time: 0.096\n",
      "step:      464, time: 0.089\n",
      "step:      465, time: 0.091\n",
      "step:      466, time: 0.097\n",
      "step:      467, time: 0.093\n",
      "step:      468, time: 0.086\n",
      "step:      469, time: 0.090\n",
      "step:      470, time: 0.091\n",
      "step:      471, time: 0.089\n",
      "step:      472, time: 0.087\n",
      "step:      473, time: 0.089\n",
      "step:      474, time: 0.092\n",
      "step:      475, time: 0.092\n",
      "step:      476, time: 0.098\n",
      "step:      477, time: 0.100\n",
      "step:      478, time: 0.091\n",
      "step:      479, time: 0.091\n",
      "step:      480, time: 0.087\n",
      "step:      481, time: 0.090\n",
      "step:      482, time: 0.099\n",
      "step:      483, time: 0.147\n",
      "step:      484, time: 0.099\n",
      "step:      485, time: 0.103\n",
      "step:      486, time: 0.088\n",
      "step:      487, time: 0.089\n",
      "step:      488, time: 0.086\n",
      "step:      489, time: 0.086\n",
      "step:      490, time: 0.088\n",
      "step:      491, time: 0.088\n",
      "step:      492, time: 0.088\n",
      "step:      493, time: 0.087\n",
      "step:      494, time: 0.087\n",
      "step:      495, time: 0.086\n",
      "step:      496, time: 0.088\n",
      "step:      497, time: 0.090\n",
      "step:      498, time: 0.083\n",
      "step:      499, time: 0.085\n",
      "step:      500, time: 0.085\n",
      "step:      501, time: 0.090\n",
      "step:      502, time: 0.089\n",
      "step:      503, time: 0.085\n",
      "step:      504, time: 0.088\n",
      "step:      505, time: 0.086\n",
      "step:      506, time: 0.107\n",
      "step:      507, time: 0.088\n",
      "step:      508, time: 0.090\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for step, inputs in enumerate(test_loader):\n",
    "        \n",
    "        iter_start_time = time.time()\n",
    "       \n",
    "\n",
    "        c_names = inputs['c_name']\n",
    "        im_names = inputs['im_name']\n",
    "        im = inputs['image'].cuda()\n",
    "        im_pose = inputs['pose_image'].cuda()\n",
    "        im_h = inputs['head'].cuda()\n",
    "        shape = inputs['shape'].cuda()\n",
    "        agnostic = inputs['agnostic'].cuda()\n",
    "        c = inputs['cloth'].cuda()\n",
    "        cm = inputs['cloth_mask'].cuda()\n",
    "        im_c = inputs['parse_cloth'].cuda()\n",
    "        im_g = inputs['grid_image'].cuda()\n",
    "        shape_ori = inputs['shape_ori']  # original body shape without blurring\n",
    "\n",
    "        grid, theta = model_gmm(agnostic, cm)\n",
    "        warped_cloth = F.grid_sample(c, grid, padding_mode='border')\n",
    "        warped_mask = F.grid_sample(cm, grid, padding_mode='zeros')\n",
    "        warped_grid = F.grid_sample(im_g, grid, padding_mode='zeros')\n",
    "        overlay = 0.7 * warped_cloth + 0.3 * im\n",
    "\n",
    "        visuals = [[im_h, shape, im_pose],\n",
    "                    [c, warped_cloth, im_c],\n",
    "                    [warped_grid, (warped_cloth+im)*0.5, im]]\n",
    "\n",
    "        save_images(warped_cloth, im_names, warp_cloth_dir)\n",
    "        save_images(warped_mask * 2 - 1, im_names, warp_mask_dir)\n",
    "        save_images(shape_ori.cuda() * 0.2 + warped_cloth *\n",
    "                    0.8, im_names, result_dir1)\n",
    "        save_images(warped_grid, im_names, warped_grid_dir)\n",
    "        save_images(overlay, im_names, overlayed_TPS_dir)\n",
    "\n",
    "        if (step+1) % opt.display_count == 0:\n",
    "            t = time.time() - iter_start_time\n",
    "            print('step: %8d, time: %.3f' % (step+1, t), flush=True)\n",
    "\n",
    "        \n",
    "        # opt.stage=\"TOM\"\n",
    "        # for idx,cloth in enumerate(c_names):\n",
    "        #     print(cloth)\n",
    "        #     cv2.imshow(cloth, c.detach().cpu().numpy()[idx].transpose(1, 2, 0))\n",
    "        #     cv2.waitKey(0)\n",
    "        #     cv2.destroyAllWindows()\n",
    "\n",
    "        # outputs = model_tom(torch.cat([agnostic, c, cm], 1))\n",
    "        # p_rendered, m_composite = torch.split(outputs, 3, 1)\n",
    "        # p_rendered = F.tanh(p_rendered)\n",
    "        # m_composite = F.sigmoid(m_composite)\n",
    "        # p_tryon = c * m_composite + p_rendered * (1 - m_composite)\n",
    "\n",
    "        # for idx,cloth in enumerate(c_names):\n",
    "        #     print(cloth)\n",
    "        #     cv2.imshow(cloth, p_rendered.detach().cpu().numpy()[idx].transpose(1, 2, 0))\n",
    "        #     cv2.waitKey(0)\n",
    "        #     cv2.destroyAllWindows()\n",
    "        # break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"data\\\\test\"\n",
    "# target = target.replace(\"\\\\\",\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warp-mask moved: data\\test\\warp-mask\n",
      "warp-cloth moved: data\\test\\warp-cloth\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "if os.path.exists(os.path.join(target, \"warp-cloth\")):\n",
    "    shutil.rmtree(os.path.join(target, \"warp-cloth\"))\n",
    "if os.path.exists(os.path.join(target, \"warp-mask\")):\n",
    "    shutil.rmtree(os.path.join(target, \"warp-mask\"))\n",
    "# os.path.join(\"result/GMM/test/warp-cloth\", target)\n",
    "\n",
    "print(\"warp-mask moved:\",shutil.move(\"result/GMM/test/warp-mask\", target))\n",
    "print(\"warp-cloth moved:\",shutil.move(\"result/GMM/test/warp-cloth\", target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opt():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # parser.add_argument(\"--name\", default=\"GMM\")\n",
    "    parser.add_argument(\"--name\", default=\"TOM\")\n",
    "\n",
    "    parser.add_argument(\"--gpu_ids\", default=\"1\")\n",
    "    parser.add_argument('-j', '--workers', type=int, default=1)\n",
    "    parser.add_argument('-b', '--batch-size', type=int, default=4)\n",
    "\n",
    "    parser.add_argument(\"--dataroot\", default=\"data\")\n",
    "\n",
    "    # parser.add_argument(\"--datamode\", default=\"train\")\n",
    "    parser.add_argument(\"--datamode\", default=\"test\")\n",
    "    # parser.add_argument(\"--datamode\", default=\"wild\")\n",
    "\n",
    "    # parser.add_argument(\"--stage\", default=\"GMM\")\n",
    "    parser.add_argument(\"--stage\", default=\"TOM\")\n",
    "\n",
    "    # parser.add_argument(\"--data_list\", default=\"train_pairs.txt\")\n",
    "    parser.add_argument(\"--data_list\", default=\"test_pairs.txt\")\n",
    "    # parser.add_argument(\"--data_list\", default=\"wild_pairs.txt\")\n",
    "    # parser.add_argument(\"--data_list\", default=\"test_pairs_same.txt\")\n",
    "\n",
    "    parser.add_argument(\"--fine_width\", type=int, default=192)\n",
    "    parser.add_argument(\"--fine_height\", type=int, default=256)\n",
    "    parser.add_argument(\"--radius\", type=int, default=5)\n",
    "    parser.add_argument(\"--grid_size\", type=int, default=5)\n",
    "\n",
    "    parser.add_argument('--tensorboard_dir', type=str,\n",
    "                        default='tensorboard', help='save tensorboard infos')\n",
    "\n",
    "    parser.add_argument('--result_dir', type=str,\n",
    "                        default='result', help='save result infos')\n",
    "\n",
    "    # parser.add_argument('--checkpoint', type=str, default='checkpoints/GMM/gmm_final.pth', help='model checkpoint for test')\n",
    "    parser.add_argument('--checkpoint', type=str, default='checkpoints/TOM/tom_final.pth', help='model checkpoint for test')\n",
    "\n",
    "    parser.add_argument(\"--display_count\", type=int, default=1)\n",
    "    parser.add_argument(\"--shuffle\", action='store_true',default=True,\n",
    "                        help='shuffle input data')\n",
    "\n",
    "    opt = parser.parse_args(args=[])\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = get_opt()\n",
    "test_dataset = CPDataset(opt)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=opt.batch_size, shuffle=opt.shuffle, num_workers=opt.workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = os.path.basename(opt.checkpoint)\n",
    "# save_dir = os.path.join(opt.result_dir, base_name, opt.datamode)\n",
    "save_dir = os.path.join(opt.result_dir, opt.name, opt.datamode)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "try_on_dir = os.path.join(save_dir, 'try-on')\n",
    "if not os.path.exists(try_on_dir):\n",
    "    os.makedirs(try_on_dir)\n",
    "p_rendered_dir = os.path.join(save_dir, 'p_rendered')\n",
    "if not os.path.exists(p_rendered_dir):\n",
    "    os.makedirs(p_rendered_dir)\n",
    "m_composite_dir = os.path.join(save_dir, 'm_composite')\n",
    "if not os.path.exists(m_composite_dir):\n",
    "    os.makedirs(m_composite_dir)\n",
    "im_pose_dir = os.path.join(save_dir, 'im_pose')\n",
    "if not os.path.exists(im_pose_dir):\n",
    "    os.makedirs(im_pose_dir)\n",
    "shape_dir = os.path.join(save_dir, 'shape')\n",
    "if not os.path.exists(shape_dir):\n",
    "    os.makedirs(shape_dir)\n",
    "im_h_dir = os.path.join(save_dir, 'im_h')\n",
    "if not os.path.exists(im_h_dir):\n",
    "    os.makedirs(im_h_dir)  # for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tom = UnetGenerator(26, 4, 6, ngf=64, norm_layer=nn.InstanceNorm2d)  # CP-VTON+\n",
    "model_tom.cuda()\n",
    "model_tom.eval()\n",
    "checkpoint_tom= \"checkpoints/TOM/tom_final.pth\"\n",
    "load_checkpoint(model_tom, checkpoint_tom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 02032!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luca9\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "c:\\Users\\luca9\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:        1, time: 0.295\n",
      "step:        2, time: 0.118\n",
      "step:        3, time: 0.116\n",
      "step:        4, time: 0.112\n",
      "step:        5, time: 0.123\n",
      "step:        6, time: 0.107\n",
      "step:        7, time: 0.117\n",
      "step:        8, time: 0.111\n",
      "step:        9, time: 0.109\n",
      "step:       10, time: 0.103\n",
      "step:       11, time: 0.103\n",
      "step:       12, time: 0.108\n",
      "step:       13, time: 0.109\n",
      "step:       14, time: 0.117\n",
      "step:       15, time: 0.115\n",
      "step:       16, time: 0.104\n",
      "step:       17, time: 0.112\n",
      "step:       18, time: 0.104\n",
      "step:       19, time: 0.099\n",
      "step:       20, time: 0.101\n",
      "step:       21, time: 0.104\n",
      "step:       22, time: 0.104\n",
      "step:       23, time: 0.102\n",
      "step:       24, time: 0.115\n",
      "step:       25, time: 0.104\n",
      "step:       26, time: 0.103\n",
      "step:       27, time: 0.104\n",
      "step:       28, time: 0.098\n",
      "step:       29, time: 0.105\n",
      "step:       30, time: 0.100\n",
      "step:       31, time: 0.111\n",
      "step:       32, time: 0.108\n",
      "step:       33, time: 0.103\n",
      "step:       34, time: 0.109\n",
      "step:       35, time: 0.107\n",
      "step:       36, time: 0.109\n",
      "step:       37, time: 0.104\n",
      "step:       38, time: 0.121\n",
      "step:       39, time: 0.108\n",
      "step:       40, time: 0.105\n",
      "step:       41, time: 0.105\n",
      "step:       42, time: 0.114\n",
      "step:       43, time: 0.138\n",
      "step:       44, time: 0.114\n",
      "step:       45, time: 0.105\n",
      "step:       46, time: 0.106\n",
      "step:       47, time: 0.112\n",
      "step:       48, time: 0.107\n",
      "step:       49, time: 0.110\n",
      "step:       50, time: 0.114\n",
      "step:       51, time: 0.119\n",
      "step:       52, time: 0.114\n",
      "step:       53, time: 0.106\n",
      "step:       54, time: 0.105\n",
      "step:       55, time: 0.114\n",
      "step:       56, time: 0.105\n",
      "step:       57, time: 0.109\n",
      "step:       58, time: 0.104\n",
      "step:       59, time: 0.119\n",
      "step:       60, time: 0.110\n",
      "step:       61, time: 0.121\n",
      "step:       62, time: 0.129\n",
      "step:       63, time: 0.143\n",
      "step:       64, time: 0.123\n",
      "step:       65, time: 0.136\n",
      "step:       66, time: 0.124\n",
      "step:       67, time: 0.133\n",
      "step:       68, time: 0.139\n",
      "step:       69, time: 0.129\n",
      "step:       70, time: 0.128\n",
      "step:       71, time: 0.111\n",
      "step:       72, time: 0.113\n",
      "step:       73, time: 0.117\n",
      "step:       74, time: 0.125\n",
      "step:       75, time: 0.122\n",
      "step:       76, time: 0.121\n",
      "step:       77, time: 0.118\n",
      "step:       78, time: 0.114\n",
      "step:       79, time: 0.111\n",
      "step:       80, time: 0.107\n",
      "step:       81, time: 0.107\n",
      "step:       82, time: 0.107\n",
      "step:       83, time: 0.105\n",
      "step:       84, time: 0.108\n",
      "step:       85, time: 0.103\n",
      "step:       86, time: 0.106\n",
      "step:       87, time: 0.108\n",
      "step:       88, time: 0.109\n",
      "step:       89, time: 0.107\n",
      "step:       90, time: 0.101\n",
      "step:       91, time: 0.105\n",
      "step:       92, time: 0.099\n",
      "step:       93, time: 0.103\n",
      "step:       94, time: 0.106\n",
      "step:       95, time: 0.104\n",
      "step:       96, time: 0.102\n",
      "step:       97, time: 0.100\n",
      "step:       98, time: 0.100\n",
      "step:       99, time: 0.101\n",
      "step:      100, time: 0.109\n",
      "step:      101, time: 0.102\n",
      "step:      102, time: 0.100\n",
      "step:      103, time: 0.101\n",
      "step:      104, time: 0.103\n",
      "step:      105, time: 0.104\n",
      "step:      106, time: 0.106\n",
      "step:      107, time: 0.103\n",
      "step:      108, time: 0.103\n",
      "step:      109, time: 0.100\n",
      "step:      110, time: 0.110\n",
      "step:      111, time: 0.100\n",
      "step:      112, time: 0.107\n",
      "step:      113, time: 0.098\n",
      "step:      114, time: 0.100\n",
      "step:      115, time: 0.101\n",
      "step:      116, time: 0.104\n",
      "step:      117, time: 0.100\n",
      "step:      118, time: 0.102\n",
      "step:      119, time: 0.101\n",
      "step:      120, time: 0.110\n",
      "step:      121, time: 0.103\n",
      "step:      122, time: 0.103\n",
      "step:      123, time: 0.102\n",
      "step:      124, time: 0.102\n",
      "step:      125, time: 0.103\n",
      "step:      126, time: 0.139\n",
      "step:      127, time: 0.104\n",
      "step:      128, time: 0.100\n",
      "step:      129, time: 0.102\n",
      "step:      130, time: 0.103\n",
      "step:      131, time: 0.100\n",
      "step:      132, time: 0.101\n",
      "step:      133, time: 0.102\n",
      "step:      134, time: 0.099\n",
      "step:      135, time: 0.098\n",
      "step:      136, time: 0.100\n",
      "step:      137, time: 0.101\n",
      "step:      138, time: 0.115\n",
      "step:      139, time: 0.101\n",
      "step:      140, time: 0.100\n",
      "step:      141, time: 0.103\n",
      "step:      142, time: 0.098\n",
      "step:      143, time: 0.099\n",
      "step:      144, time: 0.100\n",
      "step:      145, time: 0.099\n",
      "step:      146, time: 0.101\n",
      "step:      147, time: 0.099\n",
      "step:      148, time: 0.098\n",
      "step:      149, time: 0.101\n",
      "step:      150, time: 0.101\n",
      "step:      151, time: 0.105\n",
      "step:      152, time: 0.107\n",
      "step:      153, time: 0.104\n",
      "step:      154, time: 0.103\n",
      "step:      155, time: 0.099\n",
      "step:      156, time: 0.101\n",
      "step:      157, time: 0.098\n",
      "step:      158, time: 0.102\n",
      "step:      159, time: 0.103\n",
      "step:      160, time: 0.099\n",
      "step:      161, time: 0.099\n",
      "step:      162, time: 0.100\n",
      "step:      163, time: 0.100\n",
      "step:      164, time: 0.101\n",
      "step:      165, time: 0.098\n",
      "step:      166, time: 0.098\n",
      "step:      167, time: 0.099\n",
      "step:      168, time: 0.097\n",
      "step:      169, time: 0.104\n",
      "step:      170, time: 0.097\n",
      "step:      171, time: 0.098\n",
      "step:      172, time: 0.101\n",
      "step:      173, time: 0.098\n",
      "step:      174, time: 0.097\n",
      "step:      175, time: 0.101\n",
      "step:      176, time: 0.100\n",
      "step:      177, time: 0.099\n",
      "step:      178, time: 0.101\n",
      "step:      179, time: 0.103\n",
      "step:      180, time: 0.099\n",
      "step:      181, time: 0.099\n",
      "step:      182, time: 0.100\n",
      "step:      183, time: 0.103\n",
      "step:      184, time: 0.110\n",
      "step:      185, time: 0.113\n",
      "step:      186, time: 0.101\n",
      "step:      187, time: 0.103\n",
      "step:      188, time: 0.098\n",
      "step:      189, time: 0.100\n",
      "step:      190, time: 0.105\n",
      "step:      191, time: 0.105\n",
      "step:      192, time: 0.099\n",
      "step:      193, time: 0.100\n",
      "step:      194, time: 0.097\n",
      "step:      195, time: 0.100\n",
      "step:      196, time: 0.097\n",
      "step:      197, time: 0.100\n",
      "step:      198, time: 0.097\n",
      "step:      199, time: 0.097\n",
      "step:      200, time: 0.099\n",
      "step:      201, time: 0.095\n",
      "step:      202, time: 0.105\n",
      "step:      203, time: 0.103\n",
      "step:      204, time: 0.102\n",
      "step:      205, time: 0.105\n",
      "step:      206, time: 0.102\n",
      "step:      207, time: 0.102\n",
      "step:      208, time: 0.102\n",
      "step:      209, time: 0.100\n",
      "step:      210, time: 0.100\n",
      "step:      211, time: 0.100\n",
      "step:      212, time: 0.100\n",
      "step:      213, time: 0.099\n",
      "step:      214, time: 0.104\n",
      "step:      215, time: 0.105\n",
      "step:      216, time: 0.106\n",
      "step:      217, time: 0.107\n",
      "step:      218, time: 0.102\n",
      "step:      219, time: 0.097\n",
      "step:      220, time: 0.101\n",
      "step:      221, time: 0.100\n",
      "step:      222, time: 0.105\n",
      "step:      223, time: 0.107\n",
      "step:      224, time: 0.106\n",
      "step:      225, time: 0.103\n",
      "step:      226, time: 0.097\n",
      "step:      227, time: 0.101\n",
      "step:      228, time: 0.097\n",
      "step:      229, time: 0.102\n",
      "step:      230, time: 0.100\n",
      "step:      231, time: 0.099\n",
      "step:      232, time: 0.098\n",
      "step:      233, time: 0.099\n",
      "step:      234, time: 0.099\n",
      "step:      235, time: 0.100\n",
      "step:      236, time: 0.101\n",
      "step:      237, time: 0.097\n",
      "step:      238, time: 0.101\n",
      "step:      239, time: 0.104\n",
      "step:      240, time: 0.098\n",
      "step:      241, time: 0.098\n",
      "step:      242, time: 0.102\n",
      "step:      243, time: 0.101\n",
      "step:      244, time: 0.103\n",
      "step:      245, time: 0.103\n",
      "step:      246, time: 0.103\n",
      "step:      247, time: 0.103\n",
      "step:      248, time: 0.112\n",
      "step:      249, time: 0.101\n",
      "step:      250, time: 0.102\n",
      "step:      251, time: 0.102\n",
      "step:      252, time: 0.103\n",
      "step:      253, time: 0.106\n",
      "step:      254, time: 0.108\n",
      "step:      255, time: 0.106\n",
      "step:      256, time: 0.112\n",
      "step:      257, time: 0.109\n",
      "step:      258, time: 0.097\n",
      "step:      259, time: 0.099\n",
      "step:      260, time: 0.102\n",
      "step:      261, time: 0.096\n",
      "step:      262, time: 0.096\n",
      "step:      263, time: 0.099\n",
      "step:      264, time: 0.100\n",
      "step:      265, time: 0.099\n",
      "step:      266, time: 0.099\n",
      "step:      267, time: 0.101\n",
      "step:      268, time: 0.098\n",
      "step:      269, time: 0.101\n",
      "step:      270, time: 0.097\n",
      "step:      271, time: 0.096\n",
      "step:      272, time: 0.099\n",
      "step:      273, time: 0.099\n",
      "step:      274, time: 0.101\n",
      "step:      275, time: 0.105\n",
      "step:      276, time: 0.101\n",
      "step:      277, time: 0.102\n",
      "step:      278, time: 0.107\n",
      "step:      279, time: 0.103\n",
      "step:      280, time: 0.104\n",
      "step:      281, time: 0.103\n",
      "step:      282, time: 0.099\n",
      "step:      283, time: 0.102\n",
      "step:      284, time: 0.103\n",
      "step:      285, time: 0.104\n",
      "step:      286, time: 0.108\n",
      "step:      287, time: 0.100\n",
      "step:      288, time: 0.103\n",
      "step:      289, time: 0.099\n",
      "step:      290, time: 0.094\n",
      "step:      291, time: 0.100\n",
      "step:      292, time: 0.099\n",
      "step:      293, time: 0.098\n",
      "step:      294, time: 0.100\n",
      "step:      295, time: 0.098\n",
      "step:      296, time: 0.100\n",
      "step:      297, time: 0.107\n",
      "step:      298, time: 0.101\n",
      "step:      299, time: 0.101\n",
      "step:      300, time: 0.100\n",
      "step:      301, time: 0.100\n",
      "step:      302, time: 0.100\n",
      "step:      303, time: 0.101\n",
      "step:      304, time: 0.104\n",
      "step:      305, time: 0.104\n",
      "step:      306, time: 0.100\n",
      "step:      307, time: 0.098\n",
      "step:      308, time: 0.100\n",
      "step:      309, time: 0.106\n",
      "step:      310, time: 0.100\n",
      "step:      311, time: 0.109\n",
      "step:      312, time: 0.104\n",
      "step:      313, time: 0.101\n",
      "step:      314, time: 0.102\n",
      "step:      315, time: 0.098\n",
      "step:      316, time: 0.103\n",
      "step:      317, time: 0.108\n",
      "step:      318, time: 0.105\n",
      "step:      319, time: 0.108\n",
      "step:      320, time: 0.099\n",
      "step:      321, time: 0.099\n",
      "step:      322, time: 0.103\n",
      "step:      323, time: 0.102\n",
      "step:      324, time: 0.097\n",
      "step:      325, time: 0.100\n",
      "step:      326, time: 0.100\n",
      "step:      327, time: 0.100\n",
      "step:      328, time: 0.099\n",
      "step:      329, time: 0.098\n",
      "step:      330, time: 0.098\n",
      "step:      331, time: 0.101\n",
      "step:      332, time: 0.098\n",
      "step:      333, time: 0.105\n",
      "step:      334, time: 0.099\n",
      "step:      335, time: 0.100\n",
      "step:      336, time: 0.111\n",
      "step:      337, time: 0.100\n",
      "step:      338, time: 0.098\n",
      "step:      339, time: 0.100\n",
      "step:      340, time: 0.101\n",
      "step:      341, time: 0.100\n",
      "step:      342, time: 0.102\n",
      "step:      343, time: 0.112\n",
      "step:      344, time: 0.104\n",
      "step:      345, time: 0.097\n",
      "step:      346, time: 0.099\n",
      "step:      347, time: 0.102\n",
      "step:      348, time: 0.102\n",
      "step:      349, time: 0.107\n",
      "step:      350, time: 0.104\n",
      "step:      351, time: 0.102\n",
      "step:      352, time: 0.104\n",
      "step:      353, time: 0.098\n",
      "step:      354, time: 0.099\n",
      "step:      355, time: 0.098\n",
      "step:      356, time: 0.096\n",
      "step:      357, time: 0.101\n",
      "step:      358, time: 0.104\n",
      "step:      359, time: 0.098\n",
      "step:      360, time: 0.098\n",
      "step:      361, time: 0.106\n",
      "step:      362, time: 0.102\n",
      "step:      363, time: 0.099\n",
      "step:      364, time: 0.102\n",
      "step:      365, time: 0.103\n",
      "step:      366, time: 0.099\n",
      "step:      367, time: 0.100\n",
      "step:      368, time: 0.099\n",
      "step:      369, time: 0.101\n",
      "step:      370, time: 0.101\n",
      "step:      371, time: 0.101\n",
      "step:      372, time: 0.104\n",
      "step:      373, time: 0.101\n",
      "step:      374, time: 0.110\n",
      "step:      375, time: 0.106\n",
      "step:      376, time: 0.100\n",
      "step:      377, time: 0.101\n",
      "step:      378, time: 0.100\n",
      "step:      379, time: 0.105\n",
      "step:      380, time: 0.110\n",
      "step:      381, time: 0.105\n",
      "step:      382, time: 0.111\n",
      "step:      383, time: 0.100\n",
      "step:      384, time: 0.099\n",
      "step:      385, time: 0.100\n",
      "step:      386, time: 0.099\n",
      "step:      387, time: 0.100\n",
      "step:      388, time: 0.102\n",
      "step:      389, time: 0.102\n",
      "step:      390, time: 0.111\n",
      "step:      391, time: 0.103\n",
      "step:      392, time: 0.104\n",
      "step:      393, time: 0.101\n",
      "step:      394, time: 0.101\n",
      "step:      395, time: 0.104\n",
      "step:      396, time: 0.098\n",
      "step:      397, time: 0.103\n",
      "step:      398, time: 0.100\n",
      "step:      399, time: 0.102\n",
      "step:      400, time: 0.100\n",
      "step:      401, time: 0.112\n",
      "step:      402, time: 0.104\n",
      "step:      403, time: 0.100\n",
      "step:      404, time: 0.108\n",
      "step:      405, time: 0.104\n",
      "step:      406, time: 0.106\n",
      "step:      407, time: 0.106\n",
      "step:      408, time: 0.098\n",
      "step:      409, time: 0.101\n",
      "step:      410, time: 0.100\n",
      "step:      411, time: 0.110\n",
      "step:      412, time: 0.107\n",
      "step:      413, time: 0.101\n",
      "step:      414, time: 0.098\n",
      "step:      415, time: 0.100\n",
      "step:      416, time: 0.101\n",
      "step:      417, time: 0.099\n",
      "step:      418, time: 0.107\n",
      "step:      419, time: 0.100\n",
      "step:      420, time: 0.099\n",
      "step:      421, time: 0.104\n",
      "step:      422, time: 0.102\n",
      "step:      423, time: 0.098\n",
      "step:      424, time: 0.098\n",
      "step:      425, time: 0.100\n",
      "step:      426, time: 0.098\n",
      "step:      427, time: 0.098\n",
      "step:      428, time: 0.099\n",
      "step:      429, time: 0.098\n",
      "step:      430, time: 0.105\n",
      "step:      431, time: 0.102\n",
      "step:      432, time: 0.100\n",
      "step:      433, time: 0.100\n",
      "step:      434, time: 0.098\n",
      "step:      435, time: 0.100\n",
      "step:      436, time: 0.102\n",
      "step:      437, time: 0.103\n",
      "step:      438, time: 0.105\n",
      "step:      439, time: 0.101\n",
      "step:      440, time: 0.102\n",
      "step:      441, time: 0.100\n",
      "step:      442, time: 0.103\n",
      "step:      443, time: 0.103\n",
      "step:      444, time: 0.105\n",
      "step:      445, time: 0.103\n",
      "step:      446, time: 0.099\n",
      "step:      447, time: 0.105\n",
      "step:      448, time: 0.100\n",
      "step:      449, time: 0.100\n",
      "step:      450, time: 0.100\n",
      "step:      451, time: 0.119\n",
      "step:      452, time: 0.099\n",
      "step:      453, time: 0.099\n",
      "step:      454, time: 0.099\n",
      "step:      455, time: 0.100\n",
      "step:      456, time: 0.101\n",
      "step:      457, time: 0.100\n",
      "step:      458, time: 0.099\n",
      "step:      459, time: 0.100\n",
      "step:      460, time: 0.099\n",
      "step:      461, time: 0.105\n",
      "step:      462, time: 0.101\n",
      "step:      463, time: 0.100\n",
      "step:      464, time: 0.103\n",
      "step:      465, time: 0.103\n",
      "step:      466, time: 0.100\n",
      "step:      467, time: 0.105\n",
      "step:      468, time: 0.105\n",
      "step:      469, time: 0.110\n",
      "step:      470, time: 0.104\n",
      "step:      471, time: 0.107\n",
      "step:      472, time: 0.100\n",
      "step:      473, time: 0.104\n",
      "step:      474, time: 0.100\n",
      "step:      475, time: 0.105\n",
      "step:      476, time: 0.103\n",
      "step:      477, time: 0.103\n",
      "step:      478, time: 0.098\n",
      "step:      479, time: 0.100\n",
      "step:      480, time: 0.101\n",
      "step:      481, time: 0.099\n",
      "step:      482, time: 0.104\n",
      "step:      483, time: 0.098\n",
      "step:      484, time: 0.101\n",
      "step:      485, time: 0.100\n",
      "step:      486, time: 0.100\n",
      "step:      487, time: 0.099\n",
      "step:      488, time: 0.100\n",
      "step:      489, time: 0.098\n",
      "step:      490, time: 0.103\n",
      "step:      491, time: 0.100\n",
      "step:      492, time: 0.108\n",
      "step:      493, time: 0.101\n",
      "step:      494, time: 0.104\n",
      "step:      495, time: 0.098\n",
      "step:      496, time: 0.100\n",
      "step:      497, time: 0.103\n",
      "step:      498, time: 0.100\n",
      "step:      499, time: 0.101\n",
      "step:      500, time: 0.101\n",
      "step:      501, time: 0.121\n",
      "step:      502, time: 0.103\n",
      "step:      503, time: 0.100\n",
      "step:      504, time: 0.098\n",
      "step:      505, time: 0.099\n",
      "step:      506, time: 0.109\n",
      "step:      507, time: 0.106\n",
      "step:      508, time: 0.099\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print('Dataset size: %05d!' % (len(test_loader.dataset)), flush=True)\n",
    "    for step, inputs in enumerate(test_loader):\n",
    "        iter_start_time = time.time()\n",
    "\n",
    "        im_names = inputs['im_name']\n",
    "        im = inputs['image'].cuda()\n",
    "        im_pose = inputs['pose_image']\n",
    "        im_h = inputs['head']\n",
    "        shape = inputs['shape']\n",
    "\n",
    "        agnostic = inputs['agnostic'].cuda()\n",
    "        c = inputs['cloth'].cuda()\n",
    "        cm = inputs['cloth_mask'].cuda()\n",
    "\n",
    "        # outputs = model(torch.cat([agnostic, c], 1))  # CP-VTON\n",
    "        outputs = model_tom(torch.cat([agnostic, c, cm], 1))  # CP-VTON+\n",
    "        p_rendered, m_composite = torch.split(outputs, 3, 1)\n",
    "        p_rendered = F.tanh(p_rendered)\n",
    "        m_composite = F.sigmoid(m_composite)\n",
    "        p_tryon = c * m_composite + p_rendered * (1 - m_composite)\n",
    "\n",
    "        visuals = [[im_h, shape, im_pose],\n",
    "                   [c, 2*cm-1, m_composite],\n",
    "                   [p_rendered, p_tryon, im]]\n",
    "\n",
    "        \n",
    "        # cv2.imshow(\"try on\", p_tryon[0].detach().cpu().numpy().transpose(1, 2, 0))\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "\n",
    "        save_images(p_tryon, im_names, try_on_dir)\n",
    "        save_images(im_h, im_names, im_h_dir)\n",
    "        save_images(shape, im_names, shape_dir)\n",
    "        save_images(im_pose, im_names, im_pose_dir)\n",
    "        save_images(m_composite, im_names, m_composite_dir)\n",
    "        save_images(p_rendered, im_names, p_rendered_dir)  # For test data\n",
    "\n",
    "        if (step+1) % opt.display_count == 0:\n",
    "            t = time.time() - iter_start_time\n",
    "            print('step: %8d, time: %.3f' % (step+1, t), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate SSIM - optional visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: c:\\Users\\luca9\\miniconda3\\envs\\ml\\lib\\site-packages\\lpips\\weights\\v0.1\\alex.pth\n",
      "SSIM: 0.7434842484185319\n",
      "LPIPS: tensor([[[[0.2678]]]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from skimage.metrics import structural_similarity\n",
    "import lpips\n",
    "from torchvision.transforms import ToTensor, Lambda, transforms\n",
    "transform = transforms.Compose([ToTensor(),transforms.Normalize( mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])])\n",
    "\n",
    "loss_fn_alex = lpips.LPIPS(net='alex') # best forward scores\n",
    "target_dir = 'result/TOM/test/try-on'\n",
    "initial_dir = 'data/test/image'\n",
    "\n",
    "count = 0\n",
    "tot_ssim_score = 0\n",
    "tot_lpips= 0\n",
    "for filename in os.listdir(target_dir):\n",
    "    imageA = cv2.imread(target_dir + \"/\" + filename)\n",
    "    imageB = cv2.imread(initial_dir + \"/\" + filename)\n",
    "\n",
    "    \n",
    "    # 4. Convert the images to grayscale\n",
    "    grayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\n",
    "    grayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # numpy_horizontal = np.hstack((imageB , imageA))\n",
    "    # cv2.imshow('Numpy Horizontal', numpy_horizontal)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    # 5. Compute the Structural Similarity Index (SSIM) between the two\n",
    "    #    images, ensuring that the difference image is returned\n",
    "    (score, diff) = structural_similarity(grayA, grayB, full=True)\n",
    "    diff = (diff * 255).astype(\"uint8\")\n",
    "    count += 1\n",
    "    tot_ssim_score += score\n",
    "    #print(score)\n",
    "    # 6. calculate LPIPS\n",
    "    \n",
    "    #use transforms for the normalization\n",
    "    img0 = transform(imageA) # image should be RGB, IMPORTANT: normalized to [-1,1]\n",
    "    img1 = transform(imageB)\n",
    "    d = loss_fn_alex(img0, img1)\n",
    "    tot_lpips += d\n",
    "\n",
    "ssim_score = tot_ssim_score / count\n",
    "lpips_score = tot_lpips / count\n",
    "# 6. You can print only the score if you want\n",
    "print(\"SSIM: {}\".format(ssim_score))\n",
    "print(\"LPIPS: {}\".format(lpips_score.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2677542269229889"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"lena.jpg\")\n",
    "w1 = img1.shape[1]\n",
    "\n",
    "img2 = cv2.imread(\"barn.jpg\")\n",
    "w2 = img2.shape[1]\n",
    "\n",
    "img3 = cv2.imread(\"monet2.jpg\")\n",
    "w3 = img3.shape[1]\n",
    "\n",
    "# get maximum width\n",
    "ww = max(w1, w2, w3)\n",
    "\n",
    "# pad images with transparency in width\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2BGRA)\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2BGRA)\n",
    "img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2BGRA)\n",
    "img1 = cv2.copyMakeBorder(img1, 0, 0, 0, ww-w1, borderType=cv2.BORDER_CONSTANT, value=(0,0,0,0))\n",
    "img2 = cv2.copyMakeBorder(img2, 0, 0, 0, ww-w2, borderType=cv2.BORDER_CONSTANT, value=(0,0,0,0))\n",
    "img3 = cv2.copyMakeBorder(img3, 0, 0, 0, ww-w3, borderType=cv2.BORDER_CONSTANT, value=(0,0,0,0))\n",
    "\n",
    "# stack images vertically\n",
    "result = cv2.vconcat([img1, img2, img3])\n",
    "\n",
    "# write result to disk\n",
    "cv2.imwrite(\"image_stack.png\", result)\n",
    "\n",
    "cv2.imshow(\"RESULT\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHOW DIFFERENCE BETWEEN PREDICTIONS AND GROUNDTRUTH WITH DIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = imageA\n",
    "w1 = img1.shape[1]\n",
    "img2 = imageB\n",
    "w2 = img2.shape[1]\n",
    "img3 = diff\n",
    "w3 = img3.shape[1]\n",
    "\n",
    "# get maximum width\n",
    "ww = max(w1, w2, w3)\n",
    "\n",
    "# pad images with transparency in width\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2BGRA)\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2BGRA)\n",
    "img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2BGRA)\n",
    "img1 = cv2.copyMakeBorder(img1, 0, 0, 0, ww-w1, borderType=cv2.BORDER_CONSTANT, value=(0,0,0,0))\n",
    "img2 = cv2.copyMakeBorder(img2, 0, 0, 0, ww-w2, borderType=cv2.BORDER_CONSTANT, value=(0,0,0,0))\n",
    "img3 = cv2.copyMakeBorder(img3, 0, 0, 0, ww-w3, borderType=cv2.BORDER_CONSTANT, value=(0,0,0,0))\n",
    "\n",
    "# stack images vertically\n",
    "result = cv2.vconcat([img1, img2, img3])\n",
    "\n",
    "# write result to disk\n",
    "cv2.imwrite(\"image_stack.png\", result)\n",
    "\n",
    "cv2.imshow(\"RESULT\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bdb3465f43f7d16caa905e3d914a6bad88d39cba4b7b03ec8828b71d149d992"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
